{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc99d16",
   "metadata": {},
   "source": [
    "ðŸ“Œ Run Retrival Augmented Generation on files using Langchain and FAISS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97df35",
   "metadata": {},
   "source": [
    "1- Create a vector store (knowledge base) using Langchain and FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c46217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Import the needed libraries ----------------\n",
    "from VectrorStore_v1 import RAGKnowledgeBase\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "# Initialize kb\n",
    "kb_folder = r'docs'\n",
    "vectorstore_path = 'vectorstore'\n",
    "vectorstore_name = 'faiss_vectorstore'\n",
    "\n",
    "vector_store_path = vectorstore_path + '/' + vectorstore_name # path to save the vector_store \n",
    "\n",
    "kb = RAGKnowledgeBase(kb_folder, vector_store_path)\n",
    "\n",
    "# Step 1: Build index (only once, or when docs are updated)\n",
    "documentsNum, chunkNum = kb.build_vectorstore(chunk_size=1000, chunk_overlap=200)\n",
    "#print(documentsNum, chunkNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173c888",
   "metadata": {},
   "source": [
    "2- Querry the vector sotre and get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Import the needed libraries ----------------\n",
    "from querykb_v1 import queryKnowledgeBase\n",
    "import textwrap\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "# Initialize kb\n",
    "#vector_store_path =  # path to save the vector_store \n",
    "kb = queryKnowledgeBase(vector_store_path=vector_store_path)\n",
    "\n",
    "# Step 2: Load vectorstore and prompts \n",
    "kb.load_vectorstore()\n",
    "\n",
    "\n",
    "prompt_file_path = r\"prompts/System_Prompt.txt\"\n",
    "with open(prompt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        system_prompt = f.read()\n",
    "\n",
    "user_msg = \"What is the importance of vector store and knowledge base in AI?\"\n",
    "\n",
    "# Step 3: Ask questions\n",
    "response, context_sent_to_AI = kb.ask(user_msg, system_prompt, k=2)\n",
    "# To see the context sent to the AI uncomment this code below\n",
    "#print(f\"*Context sent to AI:\\n* {textwrap.fill(context_sent_to_AI, width=100)}\")\n",
    "#print(f\"*\\n\")\n",
    "\n",
    "print(f\"*AI response:\\n* {textwrap.fill(response, width=70)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc5c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff2f814",
   "metadata": {},
   "source": [
    "ðŸ“Œ Run Retrival Augmented Generation on files using a native Vector Store embedding creation locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a0e85",
   "metadata": {},
   "source": [
    "1- Create a vector store (knowledge base) embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55645ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Import the needed libraries ----------------\n",
    "from VectorStore_v2 import VectorStore\n",
    "import os\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "kb_folder = r\"docs\"\n",
    "\n",
    "vectorstore_path = \"vectorstore\"\n",
    "vectorstore_name = \"vector_store.json\"\n",
    "\n",
    "# âœ… Create folder only\n",
    "os.makedirs(vectorstore_path, exist_ok=True)\n",
    "\n",
    "# âœ… Join folder + file name\n",
    "vector_store_path = os.path.join(vectorstore_path, vectorstore_name)\n",
    "\n",
    "# Initialize Vector Store\n",
    "store = VectorStore(api_key=os.getenv(\"OPENAI_API_KEY\"), chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Extract text, create and save Vector Store\n",
    "store.exract_save_vector_store(store, kb_folder, vector_store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c35a1",
   "metadata": {},
   "source": [
    "2- Querry the vector sotre and get response using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Import the needed libraries ----------------\n",
    "import os\n",
    "from querykb_v2 import RAG\n",
    "import textwrap\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "vectorstore_path = \"vectorstore\"\n",
    "vectorstore_name = \"vector_store.json\"\n",
    "\n",
    "vectorstore_full_path = os.path.join(vectorstore_path, vectorstore_name)\n",
    "\n",
    "rag = RAG(vector_store_path=vectorstore_full_path)\n",
    "\n",
    "\n",
    "prompt_file_path = r\"prompts\\System_Prompt.txt\"\n",
    "with open(prompt_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        system_prompt = f.read()\n",
    "\n",
    "user_msg = \"What is the importance of vector store and knowledge base in AI?\"\n",
    "\n",
    "answer, used_context = rag.askAI(user_msg, system_prompt)\n",
    "\n",
    "#print(\"\\nContext used:\\n\", used_context)\n",
    "print(f\"Text: {textwrap.fill(answer, width=80)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57514e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
